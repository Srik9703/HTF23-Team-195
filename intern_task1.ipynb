{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Srik9703/HTF23-Team-195/blob/main/intern_task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYy-fyVMCor0",
        "outputId": "1b4f1697-42f3-49f1-ae93-63089fad115e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'acuration-demos' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Acuration/acuration-demos"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BEKPO3cbxObH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0H-QuuyuC92w",
        "outputId": "79a4198b-ad32-436b-9c22-96613c8adc2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acuration-demos  demo  sample_data  task1\n"
          ]
        }
      ],
      "source": [
        "!ls\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jxabs4j5HVnM"
      },
      "outputs": [],
      "source": [
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def parse_sitemap(sitemap_path):\n",
        "  try:\n",
        "    #using get req to get data\n",
        "    f=requests.get(sitemap_path)\n",
        "    k=f.content\n",
        "    #using xml parser to find all links\n",
        "    soup = BeautifulSoup(k, 'xml')\n",
        "    urls_list = []\n",
        "    #getting all the links\n",
        "    loc_tags =soup.find_all('loc')\n",
        "    #adding all links into a list\n",
        "    for i in loc_tags:\n",
        "          urls_list.append(i.get_text())\n",
        "    #print(\"no.of urls=\",len(urls_list))\n",
        "    #for i in urls_list:\n",
        "    # if \"pdf\" in i:\n",
        "    #   print(i)\n",
        "    return urls_list\n",
        "  except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8zN0FxIgzoc",
        "outputId": "75a6a601-7165-4c68-f168-8abd146f5cc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3238\n",
            "no.of pdfs= 489\n",
            "no.of other links= 2097\n"
          ]
        }
      ],
      "source": [
        "site=\"https://raw.githubusercontent.com/Acuration/acuration-data-store/main/honeywell_sitemap.xml\"\n",
        "links=parse_sitemap(site)\n",
        "print(len(links))\n",
        "k=0\n",
        "for i in links:\n",
        "  if \".pdf\" in i:\n",
        "    #print(i)\n",
        "    k+=1\n",
        "print(\"no.of pdfs=\",k)\n",
        "print(\"no.of other links=\",(len(set(links)))-k)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20hsn0bngkyn"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "o3rhvvQxnWdv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_html_and_extract_text(html_text):\n",
        "  try:\n",
        "    #using a html parser\n",
        "      soup=BeautifulSoup(html_text,'html.parser',from_encoding=\"iso-8859-1\")\n",
        "\n",
        "      for data in soup(['style', 'script']):\n",
        "          # Remove tags\n",
        "          data.decompose()\n",
        "\n",
        "      #retriving only inner text of an element\n",
        "      k=' '.join(soup.stripped_strings)\n",
        "      #removing all special characters\n",
        "      without_spcl_char=re.sub(r'[^a-zA-Z0-9\\s]+', '', k)\n",
        "      #removing extra whitespaces\n",
        "      cleaned_text=\" \".join(without_spcl_char.split())\n",
        "\n",
        "      return cleaned_text.lower()\n",
        "  except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")\n",
        "    return None\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "YYs2aKn6ucy7"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def fetch_html_content(url):\n",
        "  try:\n",
        "    data=requests.get(url)\n",
        "    return data.content\n",
        "  except Exception as e:\n",
        "        print('There was an error in fetching {}: {}'.format(url, e))\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "kng2o594vGdP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from os.path import exists\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def save_to_file(text,path,name):\n",
        "  try:\n",
        "    #check if file already exsists\n",
        "    if exists(name):\n",
        "          print('HTML file already exists')\n",
        "          return\n",
        "\n",
        "\n",
        "      #fun=open(os.path.join(path,name),\"w\")\n",
        "    with open(os.path.join(path,name),\"w\") as file:\n",
        "            file.write(str(text))\n",
        "  except Exception as e:\n",
        "        print(f'An error occurred while saving to file {name}: {e}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "response = requests.head(\"https://honeywell.com/content/dam/honeywellbt/en/documents/downloads/india-hail/unclaimed-dividends/Unclaimed-Dividend-as-on-March-31-2019.zip\")\n",
        "\n",
        "print(response.headers['Content-Type'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hL1S2GEtcwHy",
        "outputId": "22765589-3dd3-4c7c-bc8b-79842949d39f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text/html; charset=utf-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "9EIu_Q6isI-C"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import mimetypes\n",
        "\n",
        "from os.path import exists\n",
        "\n",
        "\n",
        "def crawl_url(url, folder_path):\n",
        "    #url_type= requests.head(url)\n",
        "\n",
        "    filename=url.replace(\"/\",\"_\")\n",
        "    try:\n",
        "# url is pdf\n",
        "      if filename.endswith(\".pdf\"):\n",
        "        #checking if it already exsists\n",
        "        if exists(filename):\n",
        "          print('file already exists')\n",
        "          return\n",
        "        #downloading pdf\n",
        "        response = requests.get(link)\n",
        "        pdf = open(os.path.join(folder_path,filename), 'wb')\n",
        "        pdf.write(response.content)\n",
        "        pdf.close()\n",
        "\n",
        "#other urls\n",
        "      else:\n",
        "        if exists(filename):\n",
        "          print('file already exists')\n",
        "          return\n",
        "        # Fetch the website content using requests or another library.\n",
        "        html_content = fetch_html_content(url)\n",
        "        soup=BeautifulSoup(html_content,\"html.parser\")\n",
        "\n",
        "        # Clean the HTML content using the clean_html function.\n",
        "        extracted_text = clean_html_and_extract_text(html_content)\n",
        "        # Store the HTML content and extracted text in separate files within the folder.\n",
        "        # here filename is the crawled_url_in_underscores\n",
        "\n",
        "\n",
        "        save_to_file(soup.prettify(), folder_path, f\"{filename}_html.html\")\n",
        "        save_to_file(extracted_text, folder_path, f\"{filename}_extracted_text.txt\")\n",
        "    except Exception as e:\n",
        "      print(url,e)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "jVJZg209sVk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "225f1a52-8136-4a7a-d24d-510bf7d2e820"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://honeywell.com/content/dam/honeywellbt/en/documents/downloads/Honeywell-Hungary-%C3%89ves-energetikai-szakreferensi-riport-2020-Magyar.pdf 'utf-8' codec can't decode byte 0xc9 in position 91: invalid continuation byte\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "/usr/local/lib/python3.10/dist-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "An error occurred while saving to file https:__www.honeywell.com_in_en_press_2021_10_honeywell-hometown-solutions-india-foundation-felicitated-with-mahatma-award-2021-for-covid-19-humanitarian-efforts_12_honeywell-hometown-solutions-india-foundation-felicitated-with-mahatma-award-2021-for-covid-19-humanitarian-efforts_html.html: [Errno 36] File name too long: '/content/task1/https:__www.honeywell.com_in_en_press_2021_10_honeywell-hometown-solutions-india-foundation-felicitated-with-mahatma-award-2021-for-covid-19-humanitarian-efforts_12_honeywell-hometown-solutions-india-foundation-felicitated-with-mahatma-award-2021-for-covid-19-humanitarian-efforts_html.html'\n",
            "An error occurred while saving to file https:__www.honeywell.com_in_en_press_2021_10_honeywell-hometown-solutions-india-foundation-felicitated-with-mahatma-award-2021-for-covid-19-humanitarian-efforts_12_honeywell-hometown-solutions-india-foundation-felicitated-with-mahatma-award-2021-for-covid-19-humanitarian-efforts_extracted_text.txt: [Errno 36] File name too long: '/content/task1/https:__www.honeywell.com_in_en_press_2021_10_honeywell-hometown-solutions-india-foundation-felicitated-with-mahatma-award-2021-for-covid-19-humanitarian-efforts_12_honeywell-hometown-solutions-india-foundation-felicitated-with-mahatma-award-2021-for-covid-19-humanitarian-efforts_extracted_text.txt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://honeywell.com/content/dam/honeywellbt/en/documents/downloads/india-hail/unclaimed-dividends/Unclaimed-Dividend-as-on-March-31-2019.zip unknown status keyword 'v' in marked section\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://honeywell.com/content/dam/honeywellbt/en/documents/downloads/remote-access/SWD-Cisco-AnyConnect-Registry-Cleanup-4.7.01076-ENT-ENG-A.zip unknown status keyword 'LOG' in marked section\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://honeywell.com/content/dam/honeywellbt/en/videos/N95_Master_V5.mp4 expected name token at '<![�\\x1cj��k�!\\x08y�\\x10U�Oڔ�'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n",
            "WARNING:bs4.dammit:Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import requests\n",
        "\n",
        "folder_path=\"/content/task1\"\n",
        "sitemap_path=\"https://raw.githubusercontent.com/Acuration/acuration-data-store/main/honeywell_sitemap.xml\"\n",
        "if not os.path.exists(folder_path):\n",
        "    os.makedirs(folder_path)\n",
        "    #to get list of links in siitemap\n",
        "urls_list=parse_sitemap(sitemap_path)\n",
        "\n",
        "for link in urls_list:\n",
        "    #cleaning and extracting data\n",
        "    crawl_url(link,\"/content/task1\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from os.path import exists\n",
        "\n",
        "link=\"https://honeywell.com/content/dam/honeywellbt/en/documents/downloads/Honeywell-Hungary-%C3%89ves-energetikai-szakreferensi-riport-2020-Magyar.pdf\"\n",
        "response = requests.get(link)\n",
        "pdf = open(os.path.join(\"/content/demo\",\"name\"), 'wb')\n",
        "pdf.write(response.content)\n",
        "pdf.close()"
      ],
      "metadata": {
        "id": "FyCSudxA30Ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os,os.path\n",
        "\n",
        "# simple version for working with CWD\n",
        "#print len([name for name in os.listdir('.') if os.path.isfile(name)])\n",
        "\n",
        "# path joining version for other paths\n",
        "DIR = \"/content/task1\"\n",
        "print (len([name for name in os.listdir(DIR) if os.path.isfile(os.path.join(DIR, name))]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6XPgfVxMJ_u",
        "outputId": "8ccdb704-1771-4037-8443-00bb1eea642d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQY6BDZEHha1"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkkJNSkp5VJEZ+v7m4H6JK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}